{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkqK-PL59DZC"
      },
      "outputs": [],
      "source": [
        "#!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from __future__ import print_function\n",
        "import numpy as np \n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import math \n",
        "from sklearn.cluster import KMeans, DBSCAN"
      ],
      "metadata": {
        "id": "sTZoczVs9HM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ce885f-d9f5-431a-ea25-78fe35efa0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  EPS = np.finfo(np.float).eps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall pandas -y"
      ],
      "metadata": {
        "id": "MpQZukHk9HPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas==0.25.1"
      ],
      "metadata": {
        "id": "6WnL9PeM9HR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CFaXqJB19HUP",
        "outputId": "693cfd80-a212-42b9-ab89-fe22494d7373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.25.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall scikit-learn -y"
      ],
      "metadata": {
        "id": "8_905Qum_eEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scikit-learn==0.21.2"
      ],
      "metadata": {
        "id": "4qD3FV9S_eGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wWGe-caF_eJA",
        "outputId": "248dfeb7-31e8-477e-af1e-2fe66712b1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.21.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "n4-9nfIc_eLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime \n",
        "\n",
        "def dateTimeFunction(date, time):\n",
        "  month,day,year = dateFunc(date)\n",
        "  hour,minute,second = timeFunc(time)\n",
        "  dt = datetime.datetime(int(year),int(month),int(day),int(hour),int(minute),int(second))\n",
        "  return dt\n",
        "\n",
        "def dateFunc(date):\n",
        "  if '/' in date:\n",
        "    m,d,y = date.split('/')\n",
        "    return m,d,y\n",
        "  elif '-' in date:\n",
        "    d = date.split(' ')\n",
        "    y,m,d = d[0].split('-')\n",
        "    return m,d,y\n",
        "  else:\n",
        "    #print('malfunction')\n",
        "    return None \n",
        "\n",
        "def timeFunc(time):\n",
        "  h,m,s = time.split(':')\n",
        "  return h,m,s"
      ],
      "metadata": {
        "id": "BqnpL8kWOJ8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isNaN(num):\n",
        "    return num != num"
      ],
      "metadata": {
        "id": "7c45XlNiBFCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BWZ Carb Input (grams) == 24"
      ],
      "metadata": {
        "id": "GeuvpJMNBFIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def part1_meal_noMeal(df):\n",
        "  meal_time = []\n",
        "  no_meal_time = []\n",
        "  carbs = []\n",
        "  carb = None\n",
        "\n",
        "  foundMeal = False\n",
        "\n",
        "  mealCounter = 0\n",
        "  noMealCounter = 0\n",
        "\n",
        "  tempMealTime = 0\n",
        "  tempNoMealTime = 0\n",
        "\n",
        "  for index,row in df.iterrows():\n",
        "\n",
        "    \n",
        "    if isNaN(row[24]) == False and float(row[24]) > 0.0 and foundMeal == False:\n",
        "      foundMeal = True\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2])\n",
        "      noMealCounter = 0\n",
        "      carb = row[24]\n",
        "      \n",
        "    elif isNaN(row[24]) == False and float(row[24]) > 0.0 and foundMeal == True: # rule 2\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2]) \n",
        "      mealCounter = 0\n",
        "    \n",
        "\n",
        "    if foundMeal == True:\n",
        "      mealCounter += 1\n",
        "    elif foundMeal == False:\n",
        "      if noMealCounter == 0:\n",
        "        tempNoMealTime = dateTimeFunction(row[1], row[2])\n",
        "      noMealCounter += 1\n",
        "\n",
        "\n",
        "    if noMealCounter == 24:\n",
        "      no_meal_time.append(tempNoMealTime)\n",
        "      tempNoMealTime = 0\n",
        "      noMealCounter = 0\n",
        "\n",
        "    if mealCounter == 24 and isNaN(row[24]) == False and float(row[24]) > 0.0: # rule 3\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2])\n",
        "      meal_time.append(tempMealTime)\n",
        "      carbs.append(carb)\n",
        "      carb = None\n",
        "      tempMealTime = 0\n",
        "      foundMeal = False\n",
        "      mealCounter = 0\n",
        "    elif mealCounter == 24: # rule 1\n",
        "      meal_time.append(tempMealTime)\n",
        "      carbs.append(carb)\n",
        "      carb = None\n",
        "      tempMealTime = 0\n",
        "      foundMeal = False\n",
        "      mealCounter = 0\n",
        "\n",
        "  return meal_time, no_meal_time, carbs\n"
      ],
      "metadata": {
        "id": "JRUndZAtBFQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def part1_extract_p_q(df, meal, noMeal):\n",
        "\n",
        "  # ensure first time for meal and no meal is not before start of cgm data\n",
        "  elimCount_meal = 0\n",
        "  elimCount_noMeal = 0\n",
        "  for i,r in df.iterrows():\n",
        "    dt = dateTimeFunction(r[1],r[2])\n",
        "\n",
        "    mdt = meal[elimCount_meal] \n",
        "    nmdt = noMeal[elimCount_noMeal]\n",
        "\n",
        "    if mdt < dt:\n",
        "      elimCount_meal += 1\n",
        "    \n",
        "    if nmdt < dt:\n",
        "      elimCount_noMeal += 1\n",
        "\n",
        "    if mdt > dt and nmdt > dt:\n",
        "      break\n",
        "  \n",
        "  meal = meal[elimCount_meal:]\n",
        "  noMeal = noMeal[elimCount_noMeal:]\n",
        "\n",
        "  p = []\n",
        "  q = []\n",
        "  #meal_carbs = []\n",
        "\n",
        "  mealIndex = 0\n",
        "  noMealIndex = 0\n",
        "\n",
        "  indexCounter = 0\n",
        "\n",
        "  mealDone = False\n",
        "  noMealDone = False\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    mealDateTime = meal[mealIndex]\n",
        "    noMealDateTime = noMeal[noMealIndex]\n",
        "\n",
        "    dateTime = dateTimeFunction(row[1], row[2])\n",
        "\n",
        "    if mealDateTime < noMealDateTime and mealDone == False: \n",
        "      if indexCounter > len(df) - 24:\n",
        "        mealDone = True\n",
        "      elif dateTime > mealDateTime and mealIndex < len(meal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter-6:indexCounter+24]\n",
        "        p.append(arr)\n",
        "        #meal_carbs.append(df['BWZ Carb Input (grams)'][indexCounter])\n",
        "        mealIndex += 1\n",
        "      elif dateTime > mealDateTime and mealIndex == len(meal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter-6:indexCounter+24]\n",
        "        p.append(arr)\n",
        "        #meal_carbs.append(df['BWZ Carb Input (grams)'][indexCounter])\n",
        "        mealDone = True\n",
        "\n",
        "\n",
        "    elif mealDateTime > noMealDateTime and noMealDone == False:\n",
        "      if indexCounter > len(df) - 24:\n",
        "        noMealDone = True\n",
        "      elif dateTime > noMealDateTime and noMealIndex < len(noMeal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter:indexCounter+24]\n",
        "        q.append(arr)\n",
        "        noMealIndex += 1\n",
        "      elif dateTime > noMealDateTime and noMealIndex == len(noMeal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter:indexCounter+24]\n",
        "        q.append(arr)\n",
        "        noMealDone = True      \n",
        "\n",
        "    indexCounter += 1\n",
        "  return p, q #, meal_carbs"
      ],
      "metadata": {
        "id": "C8fgAw0HBFSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_data(p,q, carbs):\n",
        "  new_p = []\n",
        "  new_q = []\n",
        "  new_carbs = []\n",
        "  x = 0\n",
        "  for i in p:\n",
        "    drop = False\n",
        "    for j in i:\n",
        "      if isNaN(j):\n",
        "        drop = True\n",
        "    if drop == False:\n",
        "      new_p.append(i)\n",
        "      new_carbs.append(carbs[x])\n",
        "    x += 1\n",
        "  \n",
        "  for i in q:\n",
        "    drop = False\n",
        "    for j in i:\n",
        "      if isNaN(j):\n",
        "        drop = True\n",
        "    if drop == False:\n",
        "      new_q.append(i)\n",
        "\n",
        "  return new_p, new_q, new_carbs"
      ],
      "metadata": {
        "id": "8SLzUBRBGUoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Part 2 : Feature Extraction\n",
        "\n",
        "# feature 1\n",
        "def feature0(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff \n",
        "\n",
        "def feature00(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 0 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff\n",
        "\n",
        "def feature000(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 6 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff \n",
        "\n",
        "# feature 1\n",
        "def feature1(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min \n",
        "\n",
        "def featureA(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 0 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min\n",
        "\n",
        "def featureAZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 6 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min \n",
        "\n",
        "# feature 2\n",
        "def feature2(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "\n",
        "def featureB(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "\n",
        "def featureBZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "  \n",
        "# feature 3,4,5,6: sinusoid frequency response ~ fast fourier transform : Pf1 , f1, Pf2, f2\n",
        "def feature_sfr_fft(x):\n",
        "  retval = []\n",
        "  fft = np.fft.fft(np.array(x))\n",
        "  for i in fft[:24]:\n",
        "    real = i.real\n",
        "    imag = i.imag \n",
        "    retval.append(real)\n",
        "    retval.append(imag) \n",
        "  return retval\n",
        "\n",
        "# feature 7: slope of cgm diff over time from meal start to cgm max\n",
        "def feature7(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope \n",
        "\n",
        "def featureC(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope\n",
        "\n",
        "def featureCZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope \n",
        "\n",
        "def feature70(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope \n",
        "\n",
        "def featureC0(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope\n",
        "\n",
        "def featureCZ0(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope \n",
        "\n",
        "def feature80(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt \n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "def featureD0(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "def featureDZ0(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt \n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "\n",
        "def feature8(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "def featureD(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "def featureDZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "\n",
        "def feature9(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "def featureE(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "def featureEZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "\n",
        "def feature10(x):\n",
        "  return max(x)\n",
        "\n",
        "def feature11(x):\n",
        "  return min(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "SM6myJQjmjTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfXB5tD49-qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def part2_feature_extraction(npq):\n",
        "  fpq = []\n",
        "\n",
        "  for i in npq: \n",
        "    f = []\n",
        "\n",
        "    f1 = feature1(i)\n",
        "    f.append(f1)\n",
        "\n",
        "    f2 = feature2(i)\n",
        "    f.append(f2)\n",
        "\n",
        "\n",
        "\n",
        "    f7 = feature7(i)\n",
        "    f.append(f7)\n",
        "\n",
        "    f8 = feature8(i)\n",
        "    f.append(f8)\n",
        "\n",
        "    f9 = feature9(i) \n",
        "    f.append(f9) \n",
        "\n",
        "\n",
        "\n",
        "    # fA = featureA(i)\n",
        "    # f.append(fA)\n",
        "\n",
        "    # fB = featureB(i)\n",
        "    # f.append(fB)\n",
        "\n",
        "    # fC = featureC(i)\n",
        "    # f.append(fC)\n",
        "\n",
        "    # fD = featureD(i)\n",
        "    # f.append(fD) \n",
        "\n",
        "    # fE = featureE(i)\n",
        "    # f.append(fE)\n",
        "\n",
        "    # fAZ = featureAZ(i)\n",
        "    # f.append(fAZ)\n",
        "\n",
        "    # fBZ = featureBZ(i)\n",
        "    # f.append(fBZ)\n",
        "\n",
        "    # fCZ = featureCZ(i)\n",
        "    # f.append(fCZ)\n",
        "\n",
        "    # fDZ = featureDZ(i)\n",
        "    # f.append(fDZ) \n",
        "\n",
        "    # fEZ = featureEZ(i)\n",
        "    # f.append(fEZ)\n",
        "\n",
        "    # f0 = feature0(i)\n",
        "    # f.append(f0)\n",
        "    \n",
        "    # f00 = feature00(i)\n",
        "    # f.append(f00)\n",
        "\n",
        "    # f000 = feature000(i)\n",
        "    # f.append(f000)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fpq.append(f)\n",
        "  \n",
        "  return fpq"
      ],
      "metadata": {
        "id": "yDwnjWqgs2qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def main():\n",
        "\n",
        "# read in data\n",
        "df_insulin = pd.read_csv('InsulinData.csv', low_memory=False)\n",
        "df_cgm = pd.read_csv('CGMData.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "1qGm7Rz5s2v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reverse order of dataframe so time is in chronological order\n",
        "df_insulin = df_insulin.iloc[::-1]\n",
        "df_cgm = df_cgm.iloc[::-1]"
      ],
      "metadata": {
        "id": "3KMTjXBZLe5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 \n",
        "meal, noMeal, carbs = part1_meal_noMeal(df_insulin)\n",
        "p, q = part1_extract_p_q(df_cgm, meal, noMeal)"
      ],
      "metadata": {
        "id": "dMv6sLpBLfAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handle missing data\n",
        "new_p, new_q, carbs = handle_missing_data(p,q, carbs)\n"
      ],
      "metadata": {
        "id": "d-MtlHY4wCIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2\n",
        "np_ = [list(i) for i in new_p]\n",
        "\n",
        "features  = part2_feature_extraction(np_)"
      ],
      "metadata": {
        "id": "NxWNhjNls24i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def numberBins(carbs):\n",
        "  mi = min(carbs)\n",
        "  ma = max(carbs)\n",
        "  diff = ma - mi\n",
        "  #print(diff)\n",
        "  numBins = math.ceil(diff/20)\n",
        "  return numBins \n",
        "\n",
        "def labelMaker(carbs, numBins):\n",
        "  labels = []\n",
        "  for carb in carbs:\n",
        "    label = math.floor(carb / 20) % numBins\n",
        "    labels.append(label)\n",
        "  return np.array(labels)\n",
        "\n",
        "def removeFeatureWithNanCarb(features, carbs):\n",
        "  new_features = []\n",
        "  new_carbs = []\n",
        "\n",
        "  for i in range(len(carbs)):\n",
        "    \n",
        "    if isNaN(carbs[i]) == False:\n",
        "      new_features.append(features[i])\n",
        "      new_carbs.append(carbs[i])\n",
        "  return new_features, new_carbs\n"
      ],
      "metadata": {
        "id": "9jPw8VT9uVhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, carbs = removeFeatureWithNanCarb(features,carbs)\n",
        "numBins = numberBins(carbs)\n",
        "labels = labelMaker(carbs, numBins)"
      ],
      "metadata": {
        "id": "Ums5ivOijjOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# project 3 k-means"
      ],
      "metadata": {
        "id": "X9vd7Tzgk2P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mf = pd.DataFrame(features)"
      ],
      "metadata": {
        "id": "NR6CJAjnt9Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=numBins)"
      ],
      "metadata": {
        "id": "gfpKm4Ulk2bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = kmeans.fit_predict(df_mf)"
      ],
      "metadata": {
        "id": "VTrVYU9qk2dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_sse = np.sum((labels - predicted)**2)"
      ],
      "metadata": {
        "id": "JHnjbW0QuPBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(kmeans_sse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "zl_8GgthuPDv",
        "outputId": "9c6b80e8-d4b9-4dd4-9099-333d1c4f3450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-9ce697b8faf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(labels, predicted, numBins):\n",
        "  entropy = []\n",
        "  total_ci = [0] * numBins\n",
        "  for i in range(numBins):\n",
        "    entropy.append([0] * numBins)\n",
        "  for i in range(len(labels)):\n",
        "    p = predicted[i]\n",
        "    l = labels[i] \n",
        "    total_ci[l] += 1 \n",
        "    entropy[p][l] = entropy[int(p)][int(l)] + 1\n",
        "  for i in range(numBins):\n",
        "    for j in range(numBins):\n",
        "      e = entropy[i][j] / total_ci[j]\n",
        "      mlog = 0\n",
        "      if e == 0:\n",
        "        mlog = 0\n",
        "      else: \n",
        "        mlog = math.log(e, numBins)\n",
        "      entropy[i][j] = -1 * e * mlog\n",
        "  return np.sum(np.array([total_ci[i] * np.sum(np.array(entropy[i])) for i in range(len(entropy))])) / sum(total_ci)"
      ],
      "metadata": {
        "id": "AnR3zfzGd0AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_entropy = entropy(labels, predicted, numBins)\n",
        "print(kmeans_entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8oD_0Abd0CQ",
        "outputId": "1bc5de8e-3a3c-4816-9ab6-29cac55a0556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8730921703433953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4ZGe8AUW6Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def purity(labels, predicted, numBins):\n",
        "#   entropy = []\n",
        "#   total_ci = [0] * numBins\n",
        "#   total_ji = [0] * numBins\n",
        "#   for i in range(numBins):\n",
        "#     entropy.append([0] * numBins)\n",
        "#   for i in range(len(labels)):\n",
        "#     p = predicted[i]\n",
        "#     l = labels[i] \n",
        "#     total_ci[l] += 1 \n",
        "#     total_ji[p] += 1\n",
        "#     entropy[p][l] = entropy[int(p)][int(l)] + 1\n",
        "#   for i in range(numBins):\n",
        "#     for j in range(numBins):\n",
        "#       e = entropy[i][j] / total_ci[j]\n",
        "#       if total_ji[j] == 0:\n",
        "#         e = 0\n",
        "#       else:\n",
        "#         e = e / total_ji[j]\n",
        "#       mlog = 0\n",
        "#       if e == 0:\n",
        "#         mlog = 0\n",
        "#       else: \n",
        "#         mlog = math.log(e) \n",
        "#         if total_ji[j] == 0:\n",
        "#           mlog = 0\n",
        "#         else:\n",
        "#           mlog = mlog / total_ji[j]\n",
        "#       entropy[i][j] = -1 * e * mlog\n",
        "#   return np.sum(np.array([total_ci[i] * np.sum(np.array(entropy[i])) for i in range(len(entropy))])) / sum(total_ci)"
      ],
      "metadata": {
        "id": "1uxmJWCIW6Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_purity = 1 - kmeans_entropy#purity(labels, predicted, numBins)\n",
        "print(kmeans_purity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_3ktfmW6aE",
        "outputId": "617954a9-5323-4522-d29c-f6beb54ae032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12690782965660474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouR41pkmW6ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbs_clustering = DBSCAN(eps=60, min_samples=1).fit_predict(df_mf)\n",
        "print(dbs_clustering)\n",
        "print(len(dbs_clustering))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HImgn7o2W6ef",
        "outputId": "712a453e-6f4c-4152-bf29-b1b875f01ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dbs_clustering)):\n",
        "  if dbs_clustering[i] == -1:\n",
        "    dbs_clustering[i] = 0\n",
        "  elif dbs_clustering[i] >= numBins:\n",
        "    dbs_clustering[i] = dbs_clustering[i] % numBins"
      ],
      "metadata": {
        "id": "qnvZtYQUeoPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dbs_clustering)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyxTwEQYfF_Y",
        "outputId": "164be091-9e19-4254-d637-f2160384c578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan_sse = np.sum((labels - dbs_clustering)**2)\n",
        "print(dbscan_sse)\n",
        "\n",
        "dbscan_entropy = entropy(labels, dbs_clustering, numBins)\n",
        "print(dbscan_entropy)\n",
        "\n",
        "dbscan_purity= 1 - dbscan_entropy #purity(labels, dbs_clustering, numBins)\n",
        "print(dbscan_purity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S97wAjYOW6i8",
        "outputId": "9b5a90e5-a256-407e-f20e-32792a94db67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1666\n",
            "0.007557154996739249\n",
            "0.9924428450032607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHwmBtPmW6lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [[kmeans_sse, dbscan_sse, kmeans_entropy, 0, kmeans_purity, 1]]"
      ],
      "metadata": {
        "id": "P0R6F8ubvXx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(predictions)\n",
        "results_df.to_csv('Result.csv', header=False, index=False)"
      ],
      "metadata": {
        "id": "onwOdSaFuPF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "yS0KGVQ0Y7G-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd50124-19c1-42ed-a2a3-5088e363d6f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2385, 1666, 0.8730921703433953, 0, 0.12690782965660474, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mQWBwLUjvD0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4fGlck55vD2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S56olmAOvD4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8weeNiBFvD6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}