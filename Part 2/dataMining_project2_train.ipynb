{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkqK-PL59DZC"
      },
      "outputs": [],
      "source": [
        "#!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from __future__ import print_function\n",
        "import numpy as np \n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "sTZoczVs9HM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall pandas -y"
      ],
      "metadata": {
        "id": "MpQZukHk9HPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas==0.25.1"
      ],
      "metadata": {
        "id": "6WnL9PeM9HR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CFaXqJB19HUP",
        "outputId": "4c815d6c-eb30-48d5-fd4d-3d83e9f8f718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.25.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall scikit-learn -y"
      ],
      "metadata": {
        "id": "8_905Qum_eEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install scikit-learn==0.21.2"
      ],
      "metadata": {
        "id": "4qD3FV9S_eGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wWGe-caF_eJA",
        "outputId": "49d680d7-9bec-44c6-d02d-9b85d7069e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.21.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "n4-9nfIc_eLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime \n",
        "\n",
        "def dateTimeFunction(date, time):\n",
        "  month,day,year = dateFunc(date)\n",
        "  hour,minute,second = timeFunc(time)\n",
        "  dt = datetime.datetime(int(year),int(month),int(day),int(hour),int(minute),int(second))\n",
        "  return dt\n",
        "\n",
        "def dateFunc(date):\n",
        "  if '/' in date:\n",
        "    m,d,y = date.split('/')\n",
        "    return m,d,y\n",
        "  elif '-' in date:\n",
        "    d = date.split(' ')\n",
        "    y,m,d = d[0].split('-')\n",
        "    return m,d,y\n",
        "  else:\n",
        "    #print('malfunction')\n",
        "    return None \n",
        "\n",
        "def timeFunc(time):\n",
        "  h,m,s = time.split(':')\n",
        "  return h,m,s"
      ],
      "metadata": {
        "id": "BqnpL8kWOJ8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isNaN(num):\n",
        "    return num != num"
      ],
      "metadata": {
        "id": "7c45XlNiBFCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BWZ Carb Input (grams) == 24"
      ],
      "metadata": {
        "id": "GeuvpJMNBFIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def part1_meal_noMeal(df):\n",
        "  meal_time = []\n",
        "  no_meal_time = []\n",
        "\n",
        "  foundMeal = False\n",
        "\n",
        "  mealCounter = 0\n",
        "  noMealCounter = 0\n",
        "\n",
        "  tempMealTime = 0\n",
        "  tempNoMealTime = 0\n",
        "\n",
        "  for index,row in df.iterrows():\n",
        "\n",
        "    \n",
        "    if isNaN(row[24]) == False and float(row[24]) > 0.0 and foundMeal == False:\n",
        "      foundMeal = True\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2])\n",
        "      noMealCounter = 0\n",
        "      \n",
        "    elif isNaN(row[24]) == False and float(row[24]) > 0.0 and foundMeal == True: # rule 2\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2]) \n",
        "      mealCounter = 0\n",
        "    \n",
        "\n",
        "    if foundMeal == True:\n",
        "      mealCounter += 1\n",
        "    elif foundMeal == False:\n",
        "      if noMealCounter == 0:\n",
        "        tempNoMealTime = dateTimeFunction(row[1], row[2])\n",
        "      noMealCounter += 1\n",
        "\n",
        "\n",
        "    if noMealCounter == 24:\n",
        "      no_meal_time.append(tempNoMealTime)\n",
        "      tempNoMealTime = 0\n",
        "      noMealCounter = 0\n",
        "\n",
        "    if mealCounter == 24 and isNaN(row[24]) == False and float(row[24]) > 0.0: # rule 3\n",
        "      tempMealTime = dateTimeFunction(row[1], row[2])\n",
        "      meal_time.append(tempMealTime)\n",
        "      tempMealTime = 0\n",
        "      foundMeal = False\n",
        "      mealCounter = 0\n",
        "    elif mealCounter == 24: # rule 1\n",
        "      meal_time.append(tempMealTime)\n",
        "      tempMealTime = 0\n",
        "      foundMeal = False\n",
        "      mealCounter = 0\n",
        "\n",
        "  return meal_time, no_meal_time\n"
      ],
      "metadata": {
        "id": "JRUndZAtBFQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def part1_extract_p_q(df, meal, noMeal):\n",
        "\n",
        "  # ensure first time for meal and no meal is not before start of cgm data\n",
        "  elimCount_meal = 0\n",
        "  elimCount_noMeal = 0\n",
        "  for i,r in df.iterrows():\n",
        "    dt = dateTimeFunction(r[1],r[2])\n",
        "\n",
        "    mdt = meal[elimCount_meal] \n",
        "    nmdt = noMeal[elimCount_noMeal]\n",
        "\n",
        "    if mdt < dt:\n",
        "      #print('SHOULD 1/2')\n",
        "      elimCount_meal += 1\n",
        "    \n",
        "    if nmdt < dt:\n",
        "      #print('SHOULD 2/2')\n",
        "      elimCount_noMeal += 1\n",
        "\n",
        "    if mdt > dt and nmdt > dt:\n",
        "      break\n",
        "  \n",
        "  meal = meal[elimCount_meal:]\n",
        "  noMeal = noMeal[elimCount_noMeal:]\n",
        "\n",
        "  p = []\n",
        "  q = []\n",
        "\n",
        "  mealIndex = 0\n",
        "  noMealIndex = 0\n",
        "\n",
        "  indexCounter = 0\n",
        "\n",
        "  mealDone = False\n",
        "  noMealDone = False\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "\n",
        "    mealDateTime = meal[mealIndex]\n",
        "    noMealDateTime = noMeal[noMealIndex]\n",
        "\n",
        "    dateTime = dateTimeFunction(row[1], row[2])\n",
        "\n",
        "    if mealDateTime < noMealDateTime and mealDone == False: \n",
        "      if indexCounter > len(df) - 24:\n",
        "        mealDone = True\n",
        "        #print(\"Big Bad 1a index counter is \" + str(indexCounter))\n",
        "      elif dateTime > mealDateTime and mealIndex < len(meal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter-6:indexCounter+24]\n",
        "        # if len(arr) != 30:\n",
        "        #   print(\"Big Bad 2b index counter is \" + str(indexCounter))\n",
        "        # else:\n",
        "        p.append(arr)\n",
        "        mealIndex += 1\n",
        "      elif dateTime > mealDateTime and mealIndex == len(meal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter-6:indexCounter+24]\n",
        "        p.append(arr)\n",
        "        mealDone = True\n",
        "\n",
        "\n",
        "    elif mealDateTime > noMealDateTime and noMealDone == False:\n",
        "      if indexCounter > len(df) - 24:\n",
        "        noMealDone = True\n",
        "        #print(\"Big Bad 3c index counter is \" + str(indexCounter))\n",
        "      elif dateTime > noMealDateTime and noMealIndex < len(noMeal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter:indexCounter+24]\n",
        "        # if len(arr) != 24:\n",
        "        #   print(\"Big Bad 4d\")\n",
        "        # else:\n",
        "        q.append(arr)\n",
        "        noMealIndex += 1\n",
        "      elif dateTime > noMealDateTime and noMealIndex == len(noMeal) - 1:\n",
        "        arr = df['Sensor Glucose (mg/dL)'][indexCounter:indexCounter+24]\n",
        "        q.append(arr)\n",
        "        noMealDone = True      \n",
        "\n",
        "    indexCounter += 1\n",
        "  return p, q"
      ],
      "metadata": {
        "id": "C8fgAw0HBFSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_data(p,q):\n",
        "  new_p = []\n",
        "  new_q = []\n",
        "  for i in p:\n",
        "    drop = False\n",
        "    for j in i:\n",
        "      if isNaN(j):\n",
        "        drop = True\n",
        "    if drop == False:\n",
        "      new_p.append(i)\n",
        "  \n",
        "  for i in q:\n",
        "    drop = False\n",
        "    for j in i:\n",
        "      if isNaN(j):\n",
        "        drop = True\n",
        "    if drop == False:\n",
        "      new_q.append(i)\n",
        "\n",
        "  return new_p, new_q"
      ],
      "metadata": {
        "id": "8SLzUBRBGUoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Part 2 : Feature Extraction\n",
        "\n",
        "# feature 1\n",
        "def feature0(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff \n",
        "\n",
        "def feature00(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 0 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff\n",
        "\n",
        "def feature000(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 6 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  return tdiff \n",
        "\n",
        "# feature 1\n",
        "def feature1(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min \n",
        "\n",
        "def featureA(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 0 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min\n",
        "\n",
        "def featureAZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = 6 #x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  tdiff = max_i - min_i\n",
        "  td_in_min = tdiff * 5\n",
        "  return td_in_min \n",
        "\n",
        "# feature 2\n",
        "def feature2(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "\n",
        "def featureB(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "\n",
        "def featureBZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  cgN = cg / cgm_min\n",
        "  return cgN \n",
        "  \n",
        "# feature 3,4,5,6: sinusoid frequency response ~ fast fourier transform : Pf1 , f1, Pf2, f2\n",
        "def feature_sfr_fft(x):\n",
        "  retval = []\n",
        "  fft = np.fft.fft(np.array(x))\n",
        "  for i in fft[:24]:\n",
        "    real = i.real\n",
        "    imag = i.imag \n",
        "    retval.append(real)\n",
        "    retval.append(imag) \n",
        "  return retval\n",
        "\n",
        "# feature 7: slope of cgm diff over time from meal start to cgm max\n",
        "def feature7(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope \n",
        "\n",
        "def featureC(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope\n",
        "\n",
        "def featureCZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope \n",
        "\n",
        "def feature70(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope \n",
        "\n",
        "def featureC0(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope\n",
        "\n",
        "def featureCZ0(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return 0\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope \n",
        "\n",
        "def feature80(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt \n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "def featureD0(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt * 5\n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "def featureDZ0(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  # dt_in_min = dt \n",
        "  slope = cg / dt \n",
        "  return slope / dt\n",
        "\n",
        "\n",
        "def feature8(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "def featureD(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "def featureDZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  min_i = x.index(cgm_min)\n",
        "  max_i = x.index(cgm_max)\n",
        "  cg = cgm_max - cgm_min\n",
        "  if cg == 0:\n",
        "    return 0\n",
        "  dt = max_i - min_i \n",
        "  if dt == 0:\n",
        "    return\n",
        "  dt_in_min = dt * 5\n",
        "  slope = cg / dt_in_min \n",
        "  return slope / dt_in_min\n",
        "\n",
        "\n",
        "def feature9(x):\n",
        "  cgm_min = min(x)\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "def featureE(x):\n",
        "  cgm_min = x[0]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "def featureEZ(x):\n",
        "  cgm_min = x[6]\n",
        "  cgm_max = max(x)\n",
        "  cg = cgm_max - cgm_min\n",
        "  return cg\n",
        "\n",
        "\n",
        "def feature10(x):\n",
        "  return max(x)\n",
        "\n",
        "def feature11(x):\n",
        "  return min(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "SM6myJQjmjTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfXB5tD49-qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def part2_feature_extraction(npq):\n",
        "  fpq = []\n",
        "\n",
        "  for i in npq: \n",
        "    f = []\n",
        "\n",
        "    f1 = feature1(i)\n",
        "    f.append(f1)\n",
        "\n",
        "    f2 = feature2(i)\n",
        "    f.append(f2)\n",
        "\n",
        "    # f3 = feature_sfr_fft(i)\n",
        "    # for fi in f3:\n",
        "    #   f.append(fi)\n",
        "\n",
        "    f7 = feature7(i)\n",
        "    f.append(f7)\n",
        "\n",
        "    f8 = feature8(i)\n",
        "    f.append(f8)\n",
        "\n",
        "    f9 = feature9(i) \n",
        "    f.append(f9) \n",
        "\n",
        "    # f10 = feature10(i)\n",
        "    # f.append(f10)\n",
        "\n",
        "    # f11 = feature11(i)\n",
        "    # f.append(f11)\n",
        "\n",
        "    fA = featureA(i)\n",
        "    f.append(fA)\n",
        "\n",
        "    fB = featureB(i)\n",
        "    f.append(fB)\n",
        "\n",
        "    fC = featureC(i)\n",
        "    f.append(fC)\n",
        "\n",
        "    fD = featureD(i)\n",
        "    f.append(fD) \n",
        "\n",
        "    fE = featureE(i)\n",
        "    f.append(fE)\n",
        "\n",
        "    fAZ = featureAZ(i)\n",
        "    f.append(fAZ)\n",
        "\n",
        "    fBZ = featureBZ(i)\n",
        "    f.append(fBZ)\n",
        "\n",
        "    fCZ = featureCZ(i)\n",
        "    f.append(fCZ)\n",
        "\n",
        "    fDZ = featureDZ(i)\n",
        "    f.append(fDZ) \n",
        "\n",
        "    fEZ = featureEZ(i)\n",
        "    f.append(fEZ)\n",
        "\n",
        "    f0 = feature0(i)\n",
        "    f.append(f0)\n",
        "    \n",
        "    f00 = feature00(i)\n",
        "    f.append(f00)\n",
        "\n",
        "    f000 = feature000(i)\n",
        "    f.append(f000)\n",
        "\n",
        "    # f70 = feature70(i)\n",
        "    # f.append(f70)\n",
        "\n",
        "    # fC0 = featureC0(i)\n",
        "    # f.append(fC0)\n",
        "\n",
        "    # fCZ0 = featureCZ0(i)\n",
        "    # f.append(fCZ0)\n",
        "\n",
        "    # f80 = feature80(i)\n",
        "    # f.append(f80)\n",
        "\n",
        "    # fD0 = featureD0(i)\n",
        "    # f.append(fD0)\n",
        "\n",
        "    # fDZ0 = featureDZ0(i)\n",
        "    # f.append(fDZ0)\n",
        "\n",
        "\n",
        "    fpq.append(f)\n",
        "  \n",
        "  return fpq"
      ],
      "metadata": {
        "id": "yDwnjWqgs2qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def main():\n",
        "\n",
        "# read in data\n",
        "df_insulin = pd.read_csv('InsulinData.csv', low_memory=False)\n",
        "df_cgm = pd.read_csv('CGMData.csv', low_memory=False)\n",
        "#\n",
        "dfi2 = pd.read_csv('Insulin_patient2.csv', low_memory=False)\n",
        "dfc2 = pd.read_csv('CGM_patient2.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "1qGm7Rz5s2v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reverse order of dataframe so time is in chronological order\n",
        "df_insulin = df_insulin.iloc[::-1]\n",
        "df_cgm = df_cgm.iloc[::-1]\n",
        "#\n",
        "dfi2 = dfi2.iloc[::-1]\n",
        "dfc2 = dfc2.iloc[::-1]"
      ],
      "metadata": {
        "id": "3KMTjXBZLe5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 \n",
        "meal, noMeal = part1_meal_noMeal(df_insulin)\n",
        "p, q = part1_extract_p_q(df_cgm, meal, noMeal)\n",
        "#\n",
        "meal2, noMeal2 = part1_meal_noMeal(dfi2.iloc[: , 1:])\n",
        "p2, q2 = part1_extract_p_q(dfc2.iloc[: , 1:], meal2, noMeal2)\n",
        "\n",
        "# handle missing data\n",
        "new_p, new_q = handle_missing_data(p,q)\n",
        "#\n",
        "new_p2, new_q2 = handle_missing_data(p2,q2)"
      ],
      "metadata": {
        "id": "dMv6sLpBLfAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2\n",
        "np_ = [list(i) for i in new_p]\n",
        "nq_ = [list(i) for i in new_q]\n",
        "#\n",
        "np2 = [list(i) for i in new_p2]\n",
        "nq2 = [list(i) for i in new_q2]\n",
        "\n",
        "fp  = part2_feature_extraction(np_)\n",
        "fq = part2_feature_extraction(nq_)\n",
        "fp2 = part2_feature_extraction(np2)\n",
        "fq2 = part2_feature_extraction(nq2)"
      ],
      "metadata": {
        "id": "NxWNhjNls24i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jPw8VT9uVhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3\n",
        "# make matrix with label vector\n",
        "meal_features = fp + fp2\n",
        "no_meal_features = fq + fq2 \n",
        "\n",
        "meal_labels = [1 for i in range(len(meal_features))]\n",
        "no_meal_labels = [0 for i in range(len(no_meal_features))]\n",
        "\n",
        "features = meal_features + no_meal_features\n",
        "labels = meal_labels + no_meal_labels\n",
        "\n",
        "matrix = []\n",
        "for i in range(len(features)):\n",
        "  matrix.append(features[i] + [labels[i]])\n",
        "\n",
        "np.random.shuffle(matrix) \n",
        "\n",
        "train_data = [] \n",
        "test_data = []  \n",
        "for i in range(len(matrix)):\n",
        "  if i / len(matrix) < 0.8:\n",
        "    train_data.append(matrix[i])\n",
        "  else:\n",
        "    test_data.append(matrix[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "Ums5ivOijjOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = [i[:-1] for i in train_data]\n",
        "train_labels = [i[-1] for i in train_data]\n",
        "\n",
        "test_features = [i[:-1] for i in test_data]\n",
        "test_labels = [i[-1] for i in test_data]"
      ],
      "metadata": {
        "id": "y-TC1xG5rutO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train with svm or decision tree\n",
        "# Use k fold cross validation on the training data to evaluate your recognition system: 80% training, 20% validation\n",
        "# precision, recall, f1 score to validate"
      ],
      "metadata": {
        "id": "ESjAoW8cuw5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(train_features, train_labels)\n",
        "scores = cross_val_score(clf, test_features, test_labels, cv=5)\n",
        "# "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3ktUrWHrZhW",
        "outputId": "53a2e5be-1a3a-45c4-dae4-51aa9165eaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:670: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_folds = np.zeros(n_samples, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "id": "Tm3kBXWLU1OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85881913-148e-449f-85a8-06021fc904e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65 accuracy with a standard deviation of 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.predict(test_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kRxXVFPP4g7",
        "outputId": "748e0814-2316-40ea-a699-8497bb9831da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX1TeEPCTYJn",
        "outputId": "09f5c6cd-ba9d-4115-b941-e38bbc3ccc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import tree\n",
        "\n",
        "clf2 = tree.DecisionTreeClassifier()\n",
        "clf2 = clf2.fit(train_features, train_labels)\n",
        "\n",
        "scores2 = cross_val_score(clf2, test_features, test_labels, cv=5)\n"
      ],
      "metadata": {
        "id": "pQbeBjKguyuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24419340-f4ce-4845-96bd-2c07ed598b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:670: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_folds = np.zeros(n_samples, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:102: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_encoded = np.zeros(y.shape, dtype=np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores2.mean(), scores2.std()))"
      ],
      "metadata": {
        "id": "6DMS1ZfCr5Au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e7d237-1ad1-4866-ac7c-9ce8abe67e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.86 accuracy with a standard deviation of 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf2.predict(test_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NIfPxYViibt",
        "outputId": "a9f02c39-2f9b-412f-94e6-dce71dd0dcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store it in pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(clf2, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "id": "WsGreJKitxhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\tWrite a function with\n",
        "# input of N x 24 cgm values matrix and\n",
        "# output of N x 1 matrix into a results.csv \n",
        "# 1 if meal, 0 if no meal"
      ],
      "metadata": {
        "id": "107Pch3kvap0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yS0KGVQ0Y7G-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}